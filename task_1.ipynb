{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/CD5yxLdCiZ3OOBfqtgHl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darkeagle011110/A.I.-Resume-Matchmaker/blob/main/task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KN2GUr6rYzuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1471ea1-df9c-4a10-b12e-f65265ff2998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.24.5)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.3 in /usr/local/lib/python3.10/dist-packages (from pymupdf) (1.24.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf\n",
        "!pip install pandas\n",
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "def extract_text_from_pdf(file_path):\n",
        "    # Open the PDF file\n",
        "    pdf_document = fitz.open(file_path)\n",
        "\n",
        "    # Initialize an empty string to hold the text\n",
        "    text = \"\"\n",
        "\n",
        "    # Iterate through each page and extract text\n",
        "    for page_num in range(len(pdf_document)):\n",
        "        page = pdf_document.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage:\n",
        "resume_path = '/final resume.pdf'\n",
        "job_description_path = '/data anyls respon.pdf'\n",
        "\n",
        "resume_text = extract_text_from_pdf(resume_path)\n",
        "job_description_text = extract_text_from_pdf(job_description_path)\n",
        "\n",
        "print(\"Resume Text:\\n\", resume_text)\n",
        "print(\"\\nJob Description Text:\\n\", job_description_text)\n",
        "\n",
        "def consolidate_data(resume_text, job_description_text):\n",
        "    \"\"\"\n",
        "    Consolidates resume and job description text into a pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        resume_text (str): The extracted text from the resume.\n",
        "        job_description_text (str): The extracted text from the job description.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The consolidated DataFrame.\n",
        "    \"\"\"\n",
        "    data = {\n",
        "        'Type': ['Resume', 'Job Description'],\n",
        "        'Text': [resume_text, job_description_text]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Consolidate the text data\n",
        "consolidated_df = consolidate_data(resume_text, job_description_text)\n",
        "\n",
        "print(consolidated_df)\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_and_normalize_text(text):\n",
        "    \"\"\"\n",
        "    Cleans and normalizes text data by converting to lowercase, removing special characters,\n",
        "    and removing stopwords.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to be cleaned and normalized.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned and normalized text.\n",
        "    \"\"\"\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Join the words back into a single string\n",
        "    cleaned_text = ' '.join(words)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Clean and normalize the text data\n",
        "cleaned_resume_text = clean_and_normalize_text(resume_text)\n",
        "cleaned_jd_text = clean_and_normalize_text(job_description_text)\n",
        "\n",
        "print(\"Cleaned Resume Text:\\n\", cleaned_resume_text)\n",
        "print(\"\\nCleaned Job Description Text:\\n\", cleaned_jd_text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzmiJsAPeHCk",
        "outputId": "bb85e1b4-7902-4f90-8a97-78c5b7b33107"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Text:\n",
            " F\n",
            "by Google Digital Garage\n",
            "FUNDAMENTAL OF DIGITAL\n",
            "MARKETING\n",
            "By Coursera\n",
            "DATA ANALYTICS\n",
            "by Semrush\n",
            "MARKET ANALTICS\n",
            "JULIANA SILVA\n",
            "CHEF\n",
            "+91 9512394720\n",
            "chaitanya.s.vibhakar42@gamil.co\n",
            "m\n",
            "PROFILE\n",
            "i am a third year computer\n",
            "engineering student. I am an aspirant\n",
            "with adaptive nature and ready to\n",
            "learn mind set. My behaviour is of\n",
            "curious person and ability of critical\n",
            "thinking.\n",
            "CERTIFICATE\n",
            "EDUCATION\n",
            "2021- Higher Secondary \n",
            "2023-Completed B.E 2nd year with\n",
            "CGPA =7+\n",
            "LANGUAGES\n",
            "ENGLISH \n",
            "HINDI\n",
            "B-401,shiv complex, near bus\n",
            "station,Vyara,Tapi,Gujarat\n",
            "GUJARATI\n",
            "CREATIVITY\n",
            "TIME MANAGEMENT\n",
            "LEADERSHIP\n",
            "TEAM WORK\n",
            "SKILLS\n",
            "DBMS\n",
            "DSA (C AND JAVA)\n",
            "OS\n",
            "COA\n",
            "OBJECT ORIENTED\n",
            "PROGRAMMING\n",
            "(JAVA)\n",
            "EXCEL AND SQL\n",
            "KNOWLEDGE\n",
            "\n",
            "\n",
            "Job Description Text:\n",
            " Data analyst   \n",
            "- An intern has to perform data collection, data cleaning, data preprocessing, data visualization.  \n",
            "- from the visual, insights which are important get extracted and get discuss with the team members.   \n",
            "- present the outcome to the stackholders and make documentation of the process and outcomes.\n",
            "\n",
            "              Type                                               Text\n",
            "0           Resume  F\\nby Google Digital Garage\\nFUNDAMENTAL OF DI...\n",
            "1  Job Description  Data analyst   \\n- An intern has to perform da...\n",
            "Cleaned Resume Text:\n",
            " f google digital garage fundamental digital marketing coursera data analytics semrush market analtics juliana silva chef chaitanyasvibhakargamilco profile third year computer engineering student aspirant adaptive nature ready learn mind set behaviour curious person ability critical thinking certificate education higher secondary completed nd year cgpa languages english hindi bshiv complex near bus stationvyaratapigujarat gujarati creativity time management leadership team work skills dbms dsa c java os coa object oriented programming java excel sql knowledge\n",
            "\n",
            "Cleaned Job Description Text:\n",
            " data analyst intern perform data collection data cleaning data preprocessing data visualization visual insights important get extracted get discuss team members present outcome stackholders make documentation process outcomes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    }
  ]
}